{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T00:26:26.046207500Z",
     "start_time": "2024-03-21T00:26:18.295809300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channel, kernel_size, stride=1, padding=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if padding is None:\n",
    "            padding = 1\n",
    "        self.conv1 = nn.Conv2d(channel, channel, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(channel, channel, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.ln1 = nn.InstanceNorm2d(channel, affine=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.conv1(x)\n",
    "        logits = F.relu(logits)\n",
    "        logits = self.conv2(logits)\n",
    "        logits = self.ln1(logits)\n",
    "        logits = logits + x\n",
    "        logits = F.relu(logits)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T00:26:44.825247400Z",
     "start_time": "2024-03-21T00:26:44.791304600Z"
    }
   },
   "id": "c67fe0c32b37dcdc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_channels=10, latent_dim=100, input_size=(2, 128, 400)):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.latent_dim = latent_channels\n",
    "        self.input_size = input_size\n",
    "        self.conv0 = nn.Conv2d(2, latent_channels, kernel_size=3)\n",
    "        self.conv1 = nn.ParameterList([nn.Conv2d(latent_channels, latent_channels, 5) for _ in range(20)])\n",
    "        self.resd1 = nn.ParameterList([ResidualBlock(latent_channels, 3) for _ in range(10)])\n",
    "        self.conv2 = nn.ParameterList([nn.Conv2d(latent_channels, latent_channels, 3) for _ in range(20)])\n",
    "        # to latent dim (20, 11, 79)\n",
    "        self.conv3 = nn.Conv2d(latent_channels, latent_channels, kernel_size=3, padding=1)\n",
    "        self.fc_mu = nn.Linear(10 * 6 * 278, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(10 * 6 * 278, latent_dim)\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        logit = self.conv0(x)\n",
    "        logit = F.relu(logit)\n",
    "\n",
    "        for layer in self.conv1:\n",
    "            logit = layer(logit)\n",
    "            logit = F.relu(logit)\n",
    "\n",
    "        for resblock in self.resd1:\n",
    "            logit = resblock(logit)\n",
    "            logit = F.relu(logit)\n",
    "\n",
    "        for layer in self.conv2:\n",
    "            logit = layer(logit)\n",
    "            logit = F.relu(logit)\n",
    "\n",
    "        logit = self.conv3(logit)\n",
    "        logit = F.relu(logit)\n",
    "\n",
    "        logit = logit.reshape(logit.size()[0], -1)\n",
    "        return self.fc_mu(logit), self.fc_logvar(logit)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_channels=10, latent_dim=100, input_size=(2, 128, 400)):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.latent_channels = latent_channels\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc1 = nn.Linear(latent_dim, 16680)\n",
    "        self.conv1 = nn.Conv2d(latent_channels, latent_channels, 3, 1, padding=1)\n",
    "        self.conv2 = nn.ParameterList([nn.ConvTranspose2d(latent_channels, latent_channels, 3, 1) for _ in range(20)])\n",
    "        self.resd1 = nn.ParameterList([ResidualBlock(latent_channels, 3) for _ in range(10)])\n",
    "        self.conv3 = nn.ParameterList([nn.ConvTranspose2d(latent_channels, latent_channels, 5) for _ in range(20)])\n",
    "        self.conv0 = nn.ConvTranspose2d(latent_channels, 2, kernel_size=3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        logit = self.fc1(x)\n",
    "        logit = F.relu(logit)\n",
    "        logit = logit.reshape(logit.size()[0], self.latent_channels, 6, 278)\n",
    "        logit = self.conv1(logit)\n",
    "        logit = F.relu(logit)\n",
    "        for resblock in self.conv2:\n",
    "            logit = resblock(logit)\n",
    "            logit = F.relu(logit)\n",
    "        for resblock in self.resd1:\n",
    "            logit = resblock(logit)\n",
    "            logit = F.relu(logit)\n",
    "        for resblock in self.conv3:\n",
    "            logit = resblock(logit)\n",
    "            logit = F.relu(logit)\n",
    "        logit = self.conv0(logit)\n",
    "        return logit\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T00:26:46.897079500Z",
     "start_time": "2024-03-21T00:26:46.793988300Z"
    }
   },
   "id": "ad430f97fcd36679",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "out: torch.Tensor = encoder(torch.randn(1, 2, 128, 400))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T00:26:49.546535600Z",
     "start_time": "2024-03-21T00:26:49.322009800Z"
    }
   },
   "id": "5204a58f3fab46",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.0765,  0.0094,  0.0191,  0.0062,  0.0088, -0.0091, -0.0235,  0.0162,\n          -0.0107,  0.0102, -0.0036,  0.0186, -0.0145,  0.0260, -0.0088, -0.0189,\n           0.0090,  0.0109,  0.0013, -0.0242,  0.0143, -0.0303,  0.0351,  0.0099,\n          -0.0115, -0.0188, -0.0197, -0.0086, -0.0129, -0.0062, -0.0023,  0.0133,\n           0.0266,  0.0086,  0.0099,  0.0322,  0.0107, -0.0196, -0.0466, -0.0203,\n           0.0008,  0.0459, -0.0278, -0.0044, -0.0037, -0.0586, -0.0058, -0.0192,\n           0.0210,  0.0105, -0.0433,  0.0386,  0.0534, -0.0230, -0.0193, -0.0197,\n           0.0102, -0.0418, -0.0044,  0.0488, -0.0149,  0.0078,  0.0243,  0.0200,\n           0.0082,  0.0331,  0.0299,  0.0489,  0.0143, -0.0111, -0.0146,  0.0182,\n          -0.0264,  0.0303,  0.0326, -0.0269, -0.0333, -0.0115, -0.0208,  0.0522,\n          -0.0436,  0.0272, -0.0214, -0.0158,  0.0414, -0.0503,  0.0275,  0.0041,\n           0.0238, -0.0295, -0.0236,  0.0496, -0.0139, -0.0379, -0.0419, -0.0204,\n           0.0170,  0.0228, -0.0438, -0.0014]], grad_fn=<AddmmBackward0>),\n tensor([[-2.8581e-02,  1.2149e-04,  2.4495e-02, -8.6584e-02,  1.2429e-02,\n          -1.6193e-02,  2.7255e-02, -1.8774e-02, -3.4738e-03, -2.1322e-02,\n          -3.8529e-02, -1.2282e-02, -9.7552e-03, -2.8446e-02,  2.1688e-02,\n          -3.2119e-02, -2.4191e-02, -1.1883e-02, -7.9798e-03, -1.1670e-02,\n          -2.4081e-03, -1.2775e-02, -1.7868e-02, -1.6159e-02,  6.2694e-03,\n           1.7740e-02, -3.5945e-02,  3.9096e-03, -5.1250e-02,  4.1643e-02,\n          -9.9941e-03,  4.1965e-02, -3.1661e-02,  4.1205e-02,  5.1068e-03,\n           2.9771e-02,  6.7784e-03, -1.0330e-02,  1.0478e-03, -3.7396e-02,\n          -3.1196e-02, -1.8968e-02,  3.8335e-02,  9.0153e-03, -4.7577e-02,\n           1.1165e-02, -2.1864e-02,  1.3373e-02, -9.9973e-03,  1.4806e-02,\n           1.8453e-02, -1.0435e-02, -6.1276e-02,  4.0850e-02, -1.7577e-02,\n           2.0905e-02, -1.0496e-02,  9.1307e-03, -5.0946e-05,  2.8631e-03,\n          -1.3320e-02, -3.7053e-02,  2.3568e-02,  1.0347e-02, -8.1614e-03,\n           3.7938e-03,  1.8097e-02, -1.8560e-02,  1.0211e-02,  2.5995e-02,\n          -2.8540e-02,  1.9487e-03, -9.7499e-03,  2.9903e-02,  7.3896e-03,\n          -5.3024e-02,  5.1322e-03,  4.2939e-03, -5.6219e-03, -3.2266e-02,\n           7.7092e-04, -1.2369e-02, -1.6646e-02, -2.1456e-02, -3.1657e-02,\n           2.1808e-02,  4.7413e-02,  1.4451e-02,  3.5882e-03, -9.1759e-03,\n          -8.9235e-03, -5.2065e-03, -5.3359e-02,  1.2489e-02, -6.3700e-03,\n           1.8579e-02,  2.5430e-02, -2.3640e-02, -3.3254e-02,  2.8488e-02]],\n        grad_fn=<AddmmBackward0>))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T00:26:52.938085400Z",
     "start_time": "2024-03-21T00:26:52.891872800Z"
    }
   },
   "id": "87ec52e731dc2b41",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "out: torch.Tensor = encoder(torch.randn(1, 2, 128, 400))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T23:36:42.598582900Z",
     "start_time": "2024-03-20T23:36:42.365015400Z"
    }
   },
   "id": "7dfaba1358939bb4",
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 2, 128, 400])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(torch.randn(1, 100)).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T00:26:55.928776600Z",
     "start_time": "2024-03-21T00:26:55.621092Z"
    }
   },
   "id": "ee3b19da62c071a6",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
